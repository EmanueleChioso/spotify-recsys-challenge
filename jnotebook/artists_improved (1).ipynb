{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute this notebook first, after execute the notebook track_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "artist_csv = \"artists.csv\"\n",
    "artist_improved_intermediate=\"tracks_improved_intermediate.csv\" # intermediate csv needed to run the second notebook\n",
    "artist_improved_intermediate_dict = \"artists_improved_intermediate.csv\" # intermediate csv needed to run the second notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import re\n",
    "import collections\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arid</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Missy Elliott</td>\n",
       "      <td>spotify:artist:2wIVse2owClT7go1WT98tk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>spotify:artist:26dSoYclwsYLMAKD3tpOr4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>spotify:artist:6vWDO969PvNqNYHIOW5v0m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>spotify:artist:31TPClRtHm23RisEBtV3X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Shaggy</td>\n",
       "      <td>spotify:artist:5EvFsr3kj42KNv97ZEnqij</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arid        artist_name                             artist_uri\n",
       "0     0      Missy Elliott  spotify:artist:2wIVse2owClT7go1WT98tk\n",
       "1     1     Britney Spears  spotify:artist:26dSoYclwsYLMAKD3tpOr4\n",
       "2     2            Beyoncé  spotify:artist:6vWDO969PvNqNYHIOW5v0m\n",
       "3     3  Justin Timberlake  spotify:artist:31TPClRtHm23RisEBtV3X7\n",
       "4     4             Shaggy  spotify:artist:5EvFsr3kj42KNv97ZEnqij"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pandas.read_csv(filepath_or_buffer=artist_csv,sep=\"\\t\",header=0,\n",
    "                usecols=['arid','artist_name','artist_uri'],\n",
    "                dtype={'arid':np.int32,'artist_name':str, 'artist_uri':str})\n",
    "df = df [['arid','artist_name','artist_uri']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295860\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "originals = df['artist_name'].values\n",
    "artists = df['artist_name'].str.lower().values\n",
    "arids = df['arid'].values\n",
    "uris = df['artist_uri'].values\n",
    "print(arids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, found 8068 instances\n"
     ]
    }
   ],
   "source": [
    "# split in main and co-artists (1st level)\n",
    "def reg(vect):\n",
    "    exp = ''\n",
    "    for s in vect:\n",
    "        exp += s + '|'\n",
    "    exp = exp [:-1]\n",
    "    return exp\n",
    "\n",
    "\n",
    "def split_main_co_artists(value, reg):\n",
    "    values = re.split(reg,str(value))\n",
    "    l = len(values)\n",
    "    main = []\n",
    "    co = []\n",
    "    if l == 1:\n",
    "        main.append(values[0])\n",
    "    elif l == 2:\n",
    "        main.append(values[0])\n",
    "        co.append(values [1])\n",
    "    else:\n",
    "        main.append(values [0])\n",
    "        for i in range(1,l):\n",
    "            co.append(values[i])\n",
    "    return main, co    \n",
    "\n",
    "#regex\n",
    "s = []\n",
    "s.append('\\s[\\(\\[]?featuring[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?featurin[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?featured[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?starring[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?feat[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?ft[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?aka[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?-[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?introducing[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?presents[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?present[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?duet\\swith[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\s[\\(\\[]?with[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\sw\\/\\s')\n",
    "s.append('\\sf\\/\\s')\n",
    "s.append('\\s?\\/\\s?')\n",
    "s.append('\\s?\\,\\s\\&\\s?')\n",
    "s.append('\\smeets?\\s')\n",
    "s.append('\\sand\\shis\\s')\n",
    "s.append('\\sand\\sher\\s')\n",
    "s.append('\\sand\\sthem\\s')\n",
    "s.append('\\s\\&\\shis\\s')\n",
    "s.append('\\s\\&\\sher\\s')\n",
    "s.append('\\s\\&\\sthem\\s')\n",
    "s.append('\\s\\&amp\\;?\\s')\n",
    "s.append('[(|)]')\n",
    "s.append('[\\[|\\]]')\n",
    "s.append('[\\{|\\}]')\n",
    "#spanish cases\n",
    "s.append('\\scon\\sla\\s')\n",
    "s.append('\\sy\\ssus?\\s')\n",
    "s.append('\\sy\\slos?\\s')\n",
    "s.append('\\spresenta\\:?\\s')\n",
    "s.append('\\scon\\s')\n",
    "s.append('\\shaz\\s')\n",
    "#other lang\n",
    "s.append('\\smit\\s')\n",
    "s.append('\\savec\\s')\n",
    "s.append('perf\\.\\s')\n",
    "s.append('\\slyr\\.\\s')\n",
    "s.append('\\sdir\\.\\s')\n",
    "#special cases\n",
    "s.append('\\sfrom\\:\\s')\n",
    "s.append('\\sed\\.\\s')\n",
    "s.append('\\s?members\\sof\\sthe\\s')\n",
    "s.append('\\s?members?\\sof\\s')\n",
    "s.append('\\svol\\.?\\s')\n",
    "s.append('\\s_\\s')\n",
    "s.append('performed\\sby\\s')\n",
    "s.append('\\spresents')\n",
    "s.append('\\s\\'presents\\'')\n",
    "s.append('\\spresents...')\n",
    "s.append('\\spresents\\:')\n",
    "s.append('\\sfeaturng\\s')\n",
    "s.append('\\sfeat\\,')\n",
    "s.append('[\\(\\[]feat[\\.\\:\\.\\,]')\n",
    "s.append('feat\\.')\n",
    "\n",
    "reg_main_co_artists = reg(s)\n",
    "\n",
    "c=0\n",
    "main_a = []\n",
    "co_a = []\n",
    "for a in artists:\n",
    "    main, co = split_main_co_artists(a,reg_main_co_artists)\n",
    "    main_a.append(main)\n",
    "    co_a.append(co)\n",
    "    if len(co) + len(main) > 1:\n",
    "        c += 1\n",
    "\n",
    "if(len(main_a) != len(co_a)):\n",
    "    print(\"ERROR\")\n",
    "else:\n",
    "    print(\"DONE, found %d instances\"%(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, found 18064 instances (17298 main artists, 766 co-artists)\n"
     ]
    }
   ],
   "source": [
    "#split artists 2nd level (split main artists and after split the co-artists )\n",
    "\n",
    "def split_artists(value, reg):\n",
    "    artists = re.split(reg,str(value))\n",
    "    return artists    \n",
    "\n",
    "#regex\n",
    "s = []\n",
    "s.append('\\sand\\s')\n",
    "s.append('\\svs\\.?')\n",
    "s.append('\\s?\\-?conducted\\sby\\s')\n",
    "s.append('\\s?directed\\sby\\s')\n",
    "s.append('\\s?arranged\\sby\\s')\n",
    "s.append('\\sx\\s')\n",
    "s.append('\\s\\&\\sco\\.')\n",
    "s.append('\\s\\&\\s')\n",
    "s.append('\\s?\\;\\s?')\n",
    "s.append('\\s?\\,\\s?')\n",
    "s.append('\\s?\\+\\s?')\n",
    "#spanish \n",
    "s.append('\\sy\\s')\n",
    "\n",
    "reg_split_artists = reg(s)\n",
    "\n",
    "main_a2 = []\n",
    "co_a2 = []\n",
    "\n",
    "# main artists\n",
    "c1 = 0\n",
    "for l_a in main_a:\n",
    "    new_l = []\n",
    "    for a in l_a:\n",
    "        mains = split_artists(a,reg_split_artists)\n",
    "        new_l = new_l + mains\n",
    "        if len(mains)>1:\n",
    "            #print (mains)\n",
    "            c1 = c1 + 1\n",
    "    main_a2.append(new_l)\n",
    "\n",
    "# co-artists\n",
    "c2 = 0\n",
    "for l_a in co_a:\n",
    "    new_l = []\n",
    "    for a in l_a:\n",
    "        co = split_artists(a,reg_split_artists)\n",
    "        new_l = new_l + co\n",
    "        if len(co)>1:\n",
    "            #print (co)\n",
    "            c2 = c2 + 1\n",
    "    co_a2.append(new_l)\n",
    "\n",
    "if(len(main_a2) != len(co_a2)):\n",
    "    print(\"ERROR\")\n",
    "else:\n",
    "    print(\"DONE, found %d instances (%d main artists, %d co-artists)\"%(c1+c2,c1,c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#explore dataset\n",
    "c=0\n",
    "ens = main_a2.copy()\n",
    "ens.append(co_a2)\n",
    "for l in ens:\n",
    "    for a in l:\n",
    "        if \"search a word\" in a:\n",
    "        #if len(a) > 40:\n",
    "            c=c+1\n",
    "            print (a)\n",
    "print (c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class artist (attributes and a couple of utility methods)\n",
    "class Artist:\n",
    "    def __init__(self, original_artist, arid, uri, \n",
    "                 main_artists = [], co_artists = [], \n",
    "                 main_artists_ids = [], co_artists_ids = [], \n",
    "                ):\n",
    "        self.arid = arid\n",
    "        self.original_artist = original_artist\n",
    "        self.main = main_artists\n",
    "        self.co = co_artists\n",
    "        self.main_ids = main_artists_ids\n",
    "        self.co_ids = co_artists_ids\n",
    "        self.uri = uri\n",
    "        self.clean_names()\n",
    "        self.shif_co_if_main_empty()\n",
    "    def clean_names(self):\n",
    "        self.main = list(map(str.strip, self.main))\n",
    "        self.co = list(map(str.strip, self.co))\n",
    "        self.main = list(filter(lambda s: s!='', self.main))\n",
    "        self.co = list(filter(lambda s: s!='', self.co))\n",
    "    def shif_co_if_main_empty(self):\n",
    "        #shift first co in main if main is empty (happens when a name of the artist start with parenthesis)\n",
    "        if len(self.co) != 0 and len(self.main) ==0:\n",
    "            self.main.append(self.co[0])\n",
    "            self.co = self.co[1:]\n",
    "        # artist with no name, actually without filter single char happens just one time\n",
    "        #if len(self.co) == 0 and len(self.main) == 0:\n",
    "            #self.main.append('None')\n",
    "    def reset_main_co_ids(self):\n",
    "        self.main_ids = []\n",
    "        self.co_ids = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the artist objects\n",
    "final_artists = []\n",
    "for i in range (0,len(main_a2)):\n",
    "    original = originals[i]\n",
    "    main = main_a2[i]\n",
    "    co = co_a2[i]\n",
    "    uri = uris[i]\n",
    "    arid = arids[i]\n",
    "    final_artists.append(Artist(original,arid,uri,main,co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \tDoc Holiday\n",
      "main: \t\t['doc holiday']\n",
      "co: \t\t[]\n",
      "main ids: \t[]\n",
      "co ids: \t[]\n",
      "id: \t\t135510\n",
      "uri: \t\tspotify:artist:7AzFGMYJyPu55Ea96Q4GY1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# stat and search for attributes\n",
    "def print_info_artist(a):\n",
    "    print (\"original: \\t%s\"%(a.original_artist))\n",
    "    print (\"main: \\t\\t%s\"%(a.main))\n",
    "    print (\"co: \\t\\t%s\"%(a.co))\n",
    "    print (\"main ids: \\t%s\"%(a.main_ids))\n",
    "    print (\"co ids: \\t%s\"%(a.co_ids))\n",
    "    print (\"id: \\t\\t%s\"%(a.arid))\n",
    "    print (\"uri: \\t\\t%s\"%(a.uri))\n",
    "    return\n",
    "\n",
    "count = 0\n",
    "for a in final_artists:\n",
    "    if a.arid == 135510:\n",
    "        print_info_artist(a)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dictionary: 284238 artist\n"
     ]
    }
   ],
   "source": [
    "# build new ids for the artists\n",
    "\n",
    "def get_new_id(name):\n",
    "    global count\n",
    "    if name not in new_dict:\n",
    "        new_dict[name] = count\n",
    "        count += 1\n",
    "    return new_dict[name]\n",
    "\n",
    "new_dict = {}\n",
    "count = 0\n",
    "\n",
    "for a in final_artists:\n",
    "    a.reset_main_co_ids()\n",
    "    for name in a.main:\n",
    "        a.main_ids.append(get_new_id(name))\n",
    "    for name in a.co:\n",
    "        a.co_ids.append(get_new_id(name))\n",
    "\n",
    "\n",
    "print ('new dictionary: %d artist'%(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: clean artist which name is a stop word\n",
    "# like: orquesta, orchestra, friends, karaoke, co., chorus, etc... (look stat analysis at the end for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artists_improved_intermediate.csv done\n"
     ]
    }
   ],
   "source": [
    "# write new data in a new csv \n",
    "\n",
    "artist_fields = ['arid','artist_uri','main_ids','co_ids','artist_name']#,'main_names','co_names']\n",
    "\n",
    "full = []\n",
    "for a in final_artists:\n",
    "    row = []\n",
    "    row.append(a.arid)\n",
    "    row.append(a.uri)\n",
    "    row.append(a.main_ids)\n",
    "    row.append(a.co_ids)\n",
    "    row.append(a.original_artist)\n",
    "    #row.append(a.main)\n",
    "    #row.append(a.co)\n",
    "    full.append(row)\n",
    "\n",
    "import csv\n",
    "with open(artist_improved_intermediate, \"w\") as f:\n",
    "    writer = csv.writer(f,delimiter = \"\\t\",)\n",
    "    writer.writerow(artist_fields)\n",
    "    writer.writerows(full)\n",
    "print (artist_improved_intermediate +\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build new dictionary usefull for the future work on extraction of artist in the tracks name\n",
    "artist_fields = ['new_arid','new_artist_name']\n",
    "\n",
    "inv_map = {v: k for k, v in new_dict.items()}\n",
    "\n",
    "if len(inv_map)!=len(new_dict):\n",
    "    print('ERROR conversion dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artists_improved_intermediate_dict.csv done\n"
     ]
    }
   ],
   "source": [
    "## write dict in csv    \n",
    "import csv\n",
    "full = []\n",
    "for i in range(0,len(inv_map)):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    row.append(inv_map[i])\n",
    "    full.append(row)\n",
    "\n",
    "with open(artist_improved_intermediate_dict, \"w\") as f:\n",
    "    writer = csv.writer(f,delimiter = \"\\t\",)\n",
    "    writer.writerow(artist_fields)\n",
    "    writer.writerows(full)\n",
    "print ( artist_improved_intermediate_dict +\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for a in inv_map:\n",
    "    row = []\n",
    "    row.append(0)\n",
    "    row.append(inv_map[a])\n",
    "    stats[a] = row\n",
    "\n",
    "for a in final_artists:\n",
    "    for i in a.main_ids:\n",
    "        stats[i][0] +=1\n",
    "    for i in a.co_ids:\n",
    "        stats[i][0] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\t\ttyler ward\n",
      "23\t\tbing crosby\n",
      "22\t\tfrank sinatra\n",
      "79\t\tchorus\n",
      "82\t\tjr.\n",
      "37\t\talex\n",
      "72\t\tvarious artists\n",
      "23\t\tkim\n",
      "28\t\tjack\n",
      "44\t\tcanton jones\n",
      "79\t\tcompany\n",
      "28\t\tfamily\n",
      "160\t\tfriends\n",
      "32\t\tlove\n",
      "53\t\tme\n",
      "22\t\tyou\n",
      "23\t\tcast\n",
      "577\t\torchestra\n",
      "24\t\tjames\n",
      "28\t\tmike\n",
      "21\t\tgrupo\n",
      "28\t\tcombo\n",
      "34\t\ti\n",
      "30\t\ta\n",
      "22\t\ts\n",
      "31\t\tjohnny\n",
      "27\t\tsingers\n",
      "31\t\tlex de azevedo\n",
      "21\t\tperformer\n",
      "33\t\tensemble\n",
      "23\t\tchris\n",
      "26\t\trdb\n",
      "37\t\tthe\n",
      "55\t\tconjunto\n",
      "127\t\torquesta\n",
      "28\t\tus\n",
      "22\t\tlata mangeshkar\n",
      "21\t\tadam\n",
      "30\t\tdavid\n",
      "25\t\tghost\n",
      "37\t\tkaraoke\n",
      "54\t\tband\n",
      "25\t\trelaxation\n",
      "21\t\t1\n",
      "21\t\tmeditation\n",
      "28\t\tpiano\n",
      "22\t\tbounty killer\n",
      "22\t\twoodie\n",
      "22\t\tbeat rabbi\n",
      "22\t\tdeepspace5\n"
     ]
    }
   ],
   "source": [
    "for e in stats:\n",
    "    a=stats[e]\n",
    "    if a[0]>20:# and a[0]<25:\n",
    "        print('%d\\t\\t%s'%(a[0],a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO now or in preprocessing, remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
