{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the artists_improved notebook first, after execute this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath\n",
    "track_csv = \"tracks.csv\"\n",
    "artist_improved_intermediate=\"tracks_improved_intermediate.csv\" # generated from previous notebook\n",
    "artist_improved_intermediate_dict = \"artists_improved_intermediate.csv\" # generated from previous notebook\n",
    "artist_improved_final = \"tracks_improved.csv\"\n",
    "artist_improved_final_dict = \"artists_improved.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import tqdm\n",
    "from utils.datareader import Datareader\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>arid</th>\n",
       "      <th>alid</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lose Control (feat. Ciara &amp; Fat Man Scoop)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Crazy In Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Rock Your Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>It Wasn't Me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tid  arid  alid                                  track_name\n",
       "0    0     0     0  Lose Control (feat. Ciara & Fat Man Scoop)\n",
       "1    1     1     1                                       Toxic\n",
       "2    2     2     2                               Crazy In Love\n",
       "3    3     3     3                              Rock Your Body\n",
       "4    4     4     4                                It Wasn't Me"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(filepath_or_buffer=track_csv,sep=\"\\t\",header=0,\n",
    "                usecols=['tid','arid','alid','track_name'],\n",
    "                dtype={'tid':np.int32,'arid':np.int32,'alid':np.int32,'track_name':str})\n",
    "df = df [['tid','arid','alid','track_name']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262292 total tracks\n"
     ]
    }
   ],
   "source": [
    "names = df['track_name'].str.lower().values\n",
    "tids = df['tid'].values\n",
    "alids = df['alid'].values\n",
    "arids = df['arid'].values\n",
    "print('%d total tracks'%tids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049361, 2262292)\n"
     ]
    }
   ],
   "source": [
    "# get the full matrix (dataset + testset)\n",
    "dr = Datareader(mode='online', only_load=True, verbose=False )\n",
    "urm = dr.get_urm()\n",
    "print(urm.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262292 / 2262292 usefull tracks (threshold >= 0)\n"
     ]
    }
   ],
   "source": [
    "# just focus on songs that appear more than 1 time (-> threshold=2)\n",
    "popularity = urm.sum(axis=0).A1\n",
    "threshold = 0\n",
    "ids_usefull_tracks = np.argwhere(popularity>=threshold)\n",
    "print('%d / %d usefull tracks (threshold >= %d)'%(ids_usefull_tracks.shape[0], popularity.shape[0], threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class track\n",
    "class Track:\n",
    "    def __init__(self, tid, alid, arid, name):\n",
    "        self.tid = tid\n",
    "        self.alid = alid\n",
    "        self.arid = arid\n",
    "        self.name = name\n",
    "        self.main_ar = []\n",
    "        self.main_ar2 = []\n",
    "        self.co_ar = []\n",
    "        self.co_ar2 = []\n",
    "        \n",
    "# explore dataset function\n",
    "def explore(string, n=10000):\n",
    "    c=0\n",
    "    for t in tracks[0:n]:\n",
    "        if string in str(t.name):\n",
    "            c+=1\n",
    "            print(t.name)\n",
    "    print('%d instances'%(c))\n",
    "\n",
    "def explore_main(string, n=10000):\n",
    "    c=0\n",
    "    for t in tracks[0:n]:\n",
    "        for a in t.main_ar:\n",
    "            if string in str(a):\n",
    "                c+=1\n",
    "                print(str(a))\n",
    "    print('%d instances'%(c))\n",
    "\n",
    "def explore_co(string, n=10000):\n",
    "    c=0\n",
    "    for t in tracks[0:n]:\n",
    "        for a in t.co_ar:\n",
    "            if string in str(a):\n",
    "                c+=1\n",
    "                print(str(a))\n",
    "    print('%d instances'%(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262292 objects Track created\n"
     ]
    }
   ],
   "source": [
    "# filter tracks above threshold and build objects\n",
    "tracks = []\n",
    "for index in ids_usefull_tracks:\n",
    "    index = int(index) #leave this or you get array and no values\n",
    "    new_track = Track(tids[index], alids[index], arids[index], names[index])\n",
    "    tracks.append(new_track)\n",
    "print('%d objects Track created'%len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, found 510532 instances on 2262292 total\n"
     ]
    }
   ],
   "source": [
    "# split in main and co-artist (1st level)\n",
    "def reg(vect):\n",
    "    exp = ''\n",
    "    for s in vect:\n",
    "        exp += s + '|'\n",
    "    exp = exp [:-1]\n",
    "    return exp\n",
    "\n",
    "def split_name(value, reg):\n",
    "    values = re.split(reg,str(value))\n",
    "    l = len(values)\n",
    "    main = []\n",
    "    co = []\n",
    "    if l == 1:\n",
    "        main.append(values[0])\n",
    "    elif l == 2:\n",
    "        main.append(values[0])\n",
    "        co.append(values [1])\n",
    "    else:\n",
    "        main.append(values [0])\n",
    "        for i in range(1,l):\n",
    "            co.append(values[i])\n",
    "    return main, co    \n",
    "\n",
    "def remove_multiple_strings(cur_string, replace_list):\n",
    "    for cur_word in replace_list:\n",
    "        cur_string = cur_string.replace(cur_word, '')\n",
    "    return cur_string\n",
    "\n",
    "\n",
    "#replace list\n",
    "r = []\n",
    "r.append('remix')\n",
    "r.append('explicit album version')\n",
    "r.append('explicit version')\n",
    "r.append('explicit')\n",
    "\n",
    "\n",
    "#regex\n",
    "s = []\n",
    "#s.append('\\(featuring\\.?(.*?)\\)')\n",
    "#s.append('\\(feat\\.?(.*?)\\)')\n",
    "#s.append('\\((.*?)\\)')\n",
    "s.append('[(|)]')\n",
    "s.append('[\\[|\\]]')\n",
    "s.append('[{|}]')\n",
    "s.append('\\s-\\s')\n",
    "#s.append('\\sfeat\\.?\\s')\n",
    "\n",
    "reg_names = reg(s)\n",
    "\n",
    "c=0\n",
    "main_a = []\n",
    "co_a = []\n",
    "\n",
    "n=len(tracks)\n",
    "\n",
    "for t in tracks[0:n]:\n",
    "    t.main_ar = []\n",
    "    t.co_ar = []\n",
    "    main, co = split_name(t.name,reg_names)\n",
    "    if (len(co)>0):\n",
    "        #print(str(main)+' % '+str(co))\n",
    "        pass\n",
    "    t.main_ar=main\n",
    "    t.co_ar=co\n",
    "    if len(t.main_ar)==0:\n",
    "        print('ERROR splitting')\n",
    "    if len(co) + len(main) > 1:\n",
    "        c += 1\n",
    "\n",
    "if(len(main_a) != len(co_a)):\n",
    "    print(\"ERROR\")\n",
    "else:\n",
    "    print(\"DONE, found %d instances on %d total\"%(c,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, found 4567 instances (5540 artist) on 2262292 total\n"
     ]
    }
   ],
   "source": [
    "# clear track names with feat and featuring no inside parenthesis\n",
    "\n",
    "# split main name with no parenthesis\n",
    "def split_artists(value, reg):\n",
    "    values = re.split(reg,str(value))\n",
    "    return values   \n",
    "\n",
    "\n",
    "def clean_names(names):\n",
    "        names = list(map(str.strip, names))\n",
    "        names = list(filter(lambda s: s!='', names))\n",
    "        return names\n",
    "        \n",
    "#split track name and artist(s)\n",
    "s=[]\n",
    "s.append('\\sfeat[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\sft[\\.\\:\\.\\,]?\\s')\n",
    "s.append('\\sfeaturing[\\.\\:\\.\\,]?\\s')\n",
    "\n",
    "#split artists\n",
    "w=[]\n",
    "w.append('\\s&\\s')\n",
    "w.append('\\sand\\s')\n",
    "w.append('\\,')\n",
    "w.append('from')\n",
    "\n",
    "regex = reg(s)\n",
    "regex2 = reg(w)\n",
    "counter=0\n",
    "counter2=0\n",
    "for t in tracks[0:n]:\n",
    "    main, co = split_name(t.main_ar[0], regex)\n",
    "    t.new_title = main[0]\n",
    "    new_co=[]\n",
    "    if (len(co)>0):\n",
    "        counter+=1       \n",
    "        for c in co:\n",
    "            new_co+=split_artists(c,regex2)\n",
    "        if len(new_co)>1:\n",
    "            pass\n",
    "            #print(new_co)\n",
    "    t.new_ar1 = clean_names(new_co)\n",
    "    counter2+=len(t.new_ar1)\n",
    "print('DONE, found %d instances (%d artist) on %d total'%(counter, counter2, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, 98885 artist extracted\n"
     ]
    }
   ],
   "source": [
    "# now the shittiest part, clear thing insides parenthesis\n",
    "word_l=[]\n",
    "word_l+=['feat','featuring','ft.']\n",
    "\n",
    "w=[]\n",
    "w.append('\\s?ft\\.?\\s')\n",
    "w.append('\\s?featuring\\.?\\s')\n",
    "w.append('\\s?feat\\.?\\s')\n",
    "w.append('\\s?feat\\.?\\s?')\n",
    "w.append('\\s&\\s')\n",
    "w.append('\\s\\\\\\s')\n",
    "w.append('\\sand\\s')\n",
    "w.append('\\s?from\\s')\n",
    "w.append('\\s?with\\s')\n",
    "w.append('\\s?extended remix\\s?')\n",
    "w.append('\\s?extended version\\s?')\n",
    "w.append('\\s?lp version\\s?')\n",
    "w.append('\\s?album version\\s?')\n",
    "w.append('\\s?version\\s?')\n",
    "w.append('\\s?remix\\s?')\n",
    "w.append('\\s?explicit\\s?')\n",
    "w.append('\\s?radio mix\\s?')\n",
    "w.append('\\s?radio edit\\s?')\n",
    "w.append('\\s?a cappella\\s?')\n",
    "w.append('\\s?originally performed by\\s?')\n",
    "w.append('\\s?performed by\\s?')\n",
    "w.append('\\s?originally by\\s?')\n",
    "\n",
    "\n",
    "w.append('\\,')\n",
    "#w.append('from')\n",
    "\n",
    "regex = reg(w)\n",
    "c=0\n",
    "for t in tracks[0:n]:\n",
    "    t.new_ar2 = []\n",
    "    for a in t.co_ar:\n",
    "        if any(xs in a for xs in word_l):\n",
    "            new_ar = split_artists(a,regex)\n",
    "            t.new_ar2 += clean_names(new_ar)\n",
    "            c+=len(t.new_ar2)\n",
    "            #print(t.new_ar2)\n",
    "print('DONE, %d artist extracted'%c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, 103354 total artists extracted\n"
     ]
    }
   ],
   "source": [
    "# merge the two list\n",
    "c=0\n",
    "for t in tracks:\n",
    "    t.new_ar = []\n",
    "    for a in t.new_ar1:\n",
    "        if a not in t.new_ar:\n",
    "            t.new_ar.append(a)\n",
    "            c+=1\n",
    "    for a in t.new_ar2:\n",
    "        if a not in t.new_ar:\n",
    "            t.new_ar.append(a)\n",
    "            c+=1\n",
    "print('DONE, %d total artists extracted'%c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df2 = pandas.read_csv(filepath_or_buffer=artist_improved_intermediate,sep=\"\\t\",header=0,\n",
    "                usecols=['arid','artist_name','main_ids','co_ids'],\n",
    "                dtype={'arid':np.int32,'artist_name':str, 'main_ids':'O','co_ids':'O'})\n",
    "df2 = df2 [['arid','main_ids','co_ids']]\n",
    "df2.head()\n",
    "arid = df2['arid'].values\n",
    "mains = df2['main_ids'].values\n",
    "cos = df2['co_ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Artist:\n",
    "    def __init__(self, mains, cos):\n",
    "        self.mains = mains\n",
    "        self.cos = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary artist ids:      old_id-> new_ids \n",
    "n=arid.shape[0]\n",
    "dic_old_new={}\n",
    "for i in range(n):\n",
    "    m = np.array(ast.literal_eval(mains[i]), dtype=np.int32).tolist()\n",
    "    c = np.array(ast.literal_eval(cos[i]), dtype=np.int32).tolist()\n",
    "    dic_old_new[arid[i]]=Artist(m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dict new artits:              new id -> name\n",
    "df3 = pandas.read_csv(filepath_or_buffer=artist_improved_intermediate_dict,sep=\"\\t\",header=0,\n",
    "                usecols=['new_arid','new_artist_name'],\n",
    "                dtype={'new_arid':np.int32,'new_artist_name':str})\n",
    "df3 = df3 [['new_arid','new_artist_name']]\n",
    "df3.head()\n",
    "new_arid = df3['new_arid'].values\n",
    "new_name = df3['new_artist_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284238\n",
      "284237\n"
     ]
    }
   ],
   "source": [
    "# dict id->name and dict name->id\n",
    "dict_id_name = {}\n",
    "dict_name_id = {}\n",
    "for i in range(new_arid.shape[0]):\n",
    "    dict_id_name[new_arid[i]]=new_name[i]\n",
    "    dict_name_id[new_name[i]]=new_arid[i]\n",
    "print(len(dict_id_name))\n",
    "print(len(dict_name_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310559\n",
      "310558\n"
     ]
    }
   ],
   "source": [
    "# now let's start the conversion\n",
    "# i consider all the extracted artist as co_artist\n",
    "counter_new_arid = max(dict_id_name)+1\n",
    "miss=0\n",
    "# add new artist in dictionary\n",
    "for t in tracks:\n",
    "    for a in t.new_ar:\n",
    "        if a not in dict_name_id:\n",
    "            miss+=1\n",
    "            dict_name_id[a]=counter_new_arid\n",
    "            dict_id_name[counter_new_arid]=a\n",
    "            counter_new_arid+=1\n",
    "print(len(dict_id_name))\n",
    "print(len(dict_name_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, add 101476 instances (103354 tot)\n"
     ]
    }
   ],
   "source": [
    "#finally add new ids to each track to co artist, that doesn't already appear in the main or co ids\n",
    "c=0\n",
    "c2=0\n",
    "for t in tracks:\n",
    "    t.new_main=dic_old_new[t.arid].mains.copy()\n",
    "    t.new_co=dic_old_new[t.arid].cos.copy()\n",
    "    for a in t.new_ar:\n",
    "        id_a = dict_name_id[a]\n",
    "        c2+=1\n",
    "        if id_a not in t.new_main and id_a not in t.new_co:\n",
    "            t.new_co.append(id_a)\n",
    "            c+=1\n",
    "print('DONE, add %d instances (%d tot)'%(c,c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artists_improved_final_dict.csv done\n"
     ]
    }
   ],
   "source": [
    "# save new dict artist\n",
    "artist_fields = ['new_arid','new_artist_name']\n",
    "\n",
    "## write dict in csv    \n",
    "import csv\n",
    "full = []\n",
    "for i in range(0,max(dict_id_name)):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    row.append(dict_id_name[i])\n",
    "    full.append(row)\n",
    "\n",
    "with open(artist_improved_final_dict, \"w\") as f:\n",
    "    writer = csv.writer(f,delimiter = \"\\t\",)\n",
    "    writer.writerow(artist_fields)\n",
    "    writer.writerows(full)\n",
    "print (artist_improved_final_dict+\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artists_improved_final.csv done\n"
     ]
    }
   ],
   "source": [
    "# save new track file\n",
    "\n",
    "artist_fields = ['tid','old_arid','alid','new_main_arids','new_co_arids','name']\n",
    "\n",
    "full = []\n",
    "\n",
    "#add new tracks\n",
    "for t in tracks:\n",
    "    row = []\n",
    "    row.append(t.tid)\n",
    "    row.append(t.arid)\n",
    "    row.append(t.alid)\n",
    "    row.append(t.new_main)\n",
    "    row.append(t.new_co)\n",
    "    row.append(t.name)\n",
    "    full.append(row)\n",
    "\n",
    "import csv\n",
    "with open(artist_improved_final, \"w\") as f:\n",
    "    writer = csv.writer(f,delimiter = \"\\t\",)\n",
    "    writer.writerow(artist_fields)\n",
    "    writer.writerows(full)\n",
    "print (artist_improved_final+\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
