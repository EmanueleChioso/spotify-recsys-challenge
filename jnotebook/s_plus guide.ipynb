{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_plus similarities package guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "##### 0. Import and setup notebook\n",
    "##### 1. Common parameters in all similarities\n",
    "##### 2. Base similarities\n",
    "##### 3. Similarities with normalization\n",
    "##### 4. Stochastic similarties: p3alpha and rp3beta\n",
    "##### 5. Feature weights and user weigths\n",
    "##### 6. S-plus similarity\n",
    "##### 7. Others (dot product, s_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import and setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import recommenders.similarity.s_plus as s_plus\n",
    "# import usefull package\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38500117 0.         0.37435622 0.89684889]\n",
      " [0.88340468 0.         0.         0.86869212]\n",
      " [0.81418451 0.14007778 0.         0.42853505]\n",
      " [0.         0.4386712  0.78135333 0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# let's create a sparse matrix\n",
    "a = sp.random(5, 4, density=0.5)\n",
    "print(a.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Common parameters in all similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing...\r",
      "Allocate memory per threads...\r",
      "Build coo matrix and remove zeros...                          \r",
      "Similarity done                     \n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.5595987  0.7675149  0.5457597  0.         0.        ]\n",
      " [0.34889656 0.5457597  0.43308023 0.         0.        ]\n",
      " [0.         0.         0.         0.40147275 0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#top k per row\n",
    "k=4\n",
    "#shrink, shrink term \n",
    "shrink = 1\n",
    "#threshold, cut values under this value\n",
    "threshold = 0.25\n",
    "# binary, if true set non zeros value at value 1\n",
    "binary = False\n",
    "#target item, calculate only the rows needed\n",
    "target_items = [1,2,3]\n",
    "#verbose = 1 print the progress 0%->100% (rows/total_rows), verbose = 0 mute\n",
    "verbose = 1\n",
    "\n",
    "s = s_plus.dot_product_similarity(a,a.T,\n",
    "                                  k=k, shrink=shrink, threshold=threshold,\n",
    "                                  binary=binary, target_items=target_items,\n",
    "                                  verbose=verbose\n",
    "                                 )\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Base similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0927064  1.1191974  0.6977931  0.2925045  0.        ]\n",
      " [1.1191974  1.5350298  1.0915194  0.         0.        ]\n",
      " [0.6977931  1.0915194  0.86616045 0.06144809 0.        ]\n",
      " [0.2925045  0.         0.06144809 0.8029455  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# dot product similarity\n",
    "s = s_plus.dot_product_similarity(a, a.T)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Similarities with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.86416477 0.7172586  0.31227538 0.        ]\n",
      " [0.86416477 1.0000001  0.9466161  0.         0.        ]\n",
      " [0.7172586  0.9466161  1.         0.07368281 0.        ]\n",
      " [0.31227538 0.         0.07368281 1.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity asymmetric with alpha 0.3\n",
    "s = s_plus.cosine_similarity(a, a.T, k=4)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.7328991  0.7086824  0.28044367 0.        ]\n",
      " [0.9192917  1.         1.0923784  0.         0.        ]\n",
      " [0.610377   0.7438346  1.         0.05883808 0.        ]\n",
      " [0.23478518 0.         0.05644639 1.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# tversky similarity with alpha 0.3 and beta 1\n",
    "s = s_plus.tversky_similarity(a, a.T, alpha=0.3, beta=1, k=4)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.7419082  0.5533325  0.18245637 0.        ]\n",
      " [0.7419082  1.         0.83343023 0.         0.        ]\n",
      " [0.5533325  0.83343023 1.         0.03822212 0.        ]\n",
      " [0.18245637 0.         0.03822212 1.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# jaccard similarity\n",
    "s = s_plus.jaccard_similarity(a, a.T)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.85183394 0.7124457  0.3086057  0.        ]\n",
      " [0.85183394 1.         0.9091486  0.         0.        ]\n",
      " [0.7124457  0.9091486  1.         0.07362995 0.        ]\n",
      " [0.3086057  0.         0.07362995 1.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# dice similarity\n",
    "s = s_plus.dice_similarity(a, a.T)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stochastic similarities: p3alpha and rp3beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13469337 0.10958983 0.13340074 0.15112123]\n",
      " [0.19313264 0.01040466 0.01813251 0.18878499]\n",
      " [0.14378694 0.06801089 0.0465383  0.12920912]\n",
      " [0.00625346 0.40242207 0.35678828 0.01356905]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# pr3 alpha similarity and rp3beta eurm\n",
    "# if you have matrix with no probabilities already applied use 'sum' (otherwise use 'none' instead of 'sum')\n",
    "urm = a\n",
    "pop = urm.sum(axis=0).A1 #popularity item urm\n",
    "s_p3alpha = s_plus.p3alpha_similarity(urm.T, urm, weight_pop_m1='sum', weight_pop_m2='sum', alpha=2)\n",
    "eurm_rp3beta = s_plus.rp3beta_eurm(urm, s_p3alpha, weight_pop=pop, beta=0.1)\n",
    "print(eurm_rp3beta.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature weights and user weights similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5131342  1.1191974  0.23259772 1.170018   0.        ]\n",
      " [1.1191974  1.5350298  0.3638398  0.         0.        ]\n",
      " [0.23259772 0.3638398  0.09405987 0.         0.        ]\n",
      " [1.170018   0.         0.         2.4420524  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# feature weights and user weights\n",
    "icm = a\n",
    "weight_feature_m1 = [1,0,2,1] #high value -> sim score higher\n",
    "weight_feature_m2 = weight_feature_m1\n",
    "weight_pop_m1 = [1,1,3,1,1] #high value -> sim score lower\n",
    "weight_pop_m2 = weight_pop_m1\n",
    "s = s_plus.popularity_feature_weight_similarity(icm, icm.T,\n",
    "                                                weight_feature_m1=weight_feature_m1, weight_feature_m2=weight_feature_m2,\n",
    "                                                weight_pop_m1=weight_pop_m1, weight_pop_m2=weight_pop_m2)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5131342  1.1191974  0.6977931  1.170018   0.        ]\n",
      " [1.1191974  1.5350298  1.0915194  0.         0.        ]\n",
      " [0.6977931  1.0915194  0.84653866 0.         0.        ]\n",
      " [1.170018   0.         0.         2.4420524  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# feature weigths (like above but just feature weights)\n",
    "icm = a\n",
    "weight_feature_m1 = [1,0,2,1] #high value -> sim score higher\n",
    "weight_feature_m2 = weight_feature_m1\n",
    "s = s_plus.feature_weight_similarity(icm, icm.T,\n",
    "                                     weight_feature_m1=weight_feature_m1,\n",
    "                                     weight_feature_m2=weight_feature_m2)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.7021246e+00 5.2256212e+00 1.0699002e+00 3.9068785e-01 0.0000000e+00]\n",
      " [5.2256212e+00 7.0175004e+00 1.6372035e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0699002e+00 1.6372035e+00 4.1841373e-01 6.8606879e-03 0.0000000e+00]\n",
      " [3.9068785e-01 0.0000000e+00 6.8606879e-03 8.7989599e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# user weights (like above but just user weights)\n",
    "icm = a\n",
    "weight_pop_m1 = [1,1,3,1,1] #high value -> sim score lower\n",
    "weight_pop_m2 = weight_pop_m1\n",
    "s = s_plus.popularity_feature_weight_similarity(icm, icm.T,\n",
    "                                                weight_pop_m1=weight_pop_m1,\n",
    "                                                weight_pop_m2=weight_pop_m2)\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. S-plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9165111  0.8551227  0.6196204  0.         0.        ]\n",
      " [0.72883564 0.92291987 0.7537994  0.         0.        ]\n",
      " [0.66097873 0.9508436  0.9239521  0.         0.        ]\n",
      " [0.2836523  0.         0.03165975 0.9693384  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# s_plus similarity\n",
    "# let's use normalization term with tversky weight 0.3 (and so cosine weight 0.7 = (1-0.3)) (l)\n",
    "# (with normalization term=True value are between [0,1])\n",
    "# tversky parameters: alpha=1, beta=1 (t1, t2)\n",
    "# cosine asymmetric: alpha=0.4 (c)\n",
    "# feture weight m1: sum\n",
    "# other weight terms: none\n",
    "# top k: k=3\n",
    "s = s_plus.s_plus_similarity(a,a.T,\n",
    "                             weight_feature_m1='sum', weight_feature_m2='none',\n",
    "                             weight_pop_m1='none', weight_pop_m2='none',\n",
    "                             normalization=True, l=0.3,\n",
    "                             t1=1, t2=1,\n",
    "                             c=0.4,\n",
    "                             k=3\n",
    "                            )\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Others (dot_product, s_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.43268034]\n",
      " [0.39701307 0.5345665  1.3327124  0.         1.1210891 ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# dot_product, calculate ony rows 1 and 2\n",
    "b = sp.random(4, 3, density=0.5)\n",
    "c = sp.random(3, 5, density=0.5)\n",
    "d = s_plus.dot_product_similarity(b, c, target_items=[1,2])\n",
    "print(d.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.256934   1.0226527  0.8109543  0.         0.        ]\n",
      " [1.0430963  1.2836556  1.1547375  0.         0.        ]\n",
      " [0.8004119  1.1163211  1.2387949  0.         0.        ]\n",
      " [0.30479366 0.         0.06763485 1.2329017  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# s_plus (no more a similarity)\n",
    "# let's use normalization term with tversky weight 0.3 cosine weight 0.5 (l1, l2)\n",
    "# tversky parameters: alpha=1, beta=1 (t1, t2)\n",
    "# cosine asymmetric: alpha_x=0.4 alpha_y=0.5 (c1,c2)\n",
    "# feture weight items: sum\n",
    "# other weight terms: none\n",
    "# top k: k=3\n",
    "s = s_plus.s_plus(a,a.T,\n",
    "                             weight_feature_items='sum', weight_feature_users='none',\n",
    "                             weight_pop_items='none', weight_pop_users='none',\n",
    "                             normalization=True, l1=0.3, l2=0.5,\n",
    "                             t1=1, t2=1,\n",
    "                             c1=0.4, c2=0.5,\n",
    "                             k=3\n",
    "                            )\n",
    "print(s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
